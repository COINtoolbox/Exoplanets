N_GC = GCS$N_GC,
MBH = GCS$MBH,
errN_GC = GCS$N_GC_err,
N = nrow(GCS),
errMBH = upMBH,
MBHx = MBHx,
M = 500
)
model.NB <- "model{
# Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Prior for size
size~dunif(0.001,10)
# Hyperpriors
meanx ~ dgamma(0.01,0.01)
varx ~ dgamma(0.01,0.01)
for (i in 1:N){
MBHtrue[i] ~ dgamma(meanx^2/varx,meanx/varx)
}
# Likelihood function
for (i in 1:N){
MBH[i]~dnorm(MBHtrue[i],1/errMBH[i]^2);
errorN[i]~dbin(0.5,2*errN_GC[i])
eta[i]<-beta.0+beta.1*MBHtrue[i]
log(mu[i])<-log(exp(eta[i])+errorN[i]-errN_GC[i])
#log(mu[i])<-max(-20,min(20,eta[i]))# Ensures that large beta values do not cause numerical problems.
#p[i]<-size/(size+mu[i])
#N_GC[i]~dnegbin(p[i],size)
#Using mixture of Poisson and Gamma
N_GC[i]~dpois(g[i])
g[i]~dgamma(size,rateParm[i])
rateParm[i]<-size/mu[i]
# Prediction
#etaTrue[i]<-beta.0+beta.1*MBHtrue[i]
#log(muTrue[i])<-max(-20,min(20,etaTrue[i]))
#pTrue[i]<-size/(size+muTrue[i])
#prediction.NB[i]~dnegbin(pTrue[i],size)
# Discrepancy measures
YNew[i] ~ dnegbin(p[i],size)
expY[i] <- mu[i]
varY[i] <- mu[i] + pow(mu[i],2) / size
PRes[i] <-(N_GC[i] - expY[i])/sqrt(varY[i])
PResNew[i] <-(YNew[i] - expY[i])/sqrt(varY[i])
D[i]<-pow(PRes[i],2)
DNew[i]<-pow(PResNew[i],2)
}
Fit<-sum(D[1:N])
New<-sum(DNew[1:N])
# Prediction for new data
for (j in 1:M){
etax[j]<-beta.0+beta.1*MBHx[j]
log(mux[j])<-max(-20,min(20,etax[j]))
#px[j]<-size/(size+mux[j])
#prediction.NBx[j]~dnegbin(px[j],size)
prediction.NBx[j]~dpois(gx[j])
gx[j]~dgamma(size,rateParmx[j])
rateParmx[j]<-size/mux[j]
}
}"
inits1 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
inits2 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
inits3 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
params <- c("beta.0","beta.1","size","PRes","prediction.NB","MBHtrue","Fit","New","prediction.NBx")
#inits1<-function(){list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))}
#jags.neg <- jags.model(
#  data = jags.data,
#  inits = inits,
#  textConnection(model.NB),
#  n.chains = 3,
#  n.adapt=1000
#)
library(parallel)
cl <- makeCluster(3)
jags.neg <- run.jags(method="rjparallel", method.options=list(cl=cl),
data = jags.data,
inits = list(inits1,inits2,inits3),
model=model.NB,
n.chains = 3,
adapt=2000,
monitor=c(params),
burnin=20000,
sample=50000,
summarise=FALSE,
plots=FALSE
)
jagssamples.nb <- as.mcmc.list(jags.neg )
model.NB <- "model{
# Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Prior for size
size~dunif(0.001,10)
# Hyperpriors
meanx ~ dgamma(0.01,0.01)
varx ~ dgamma(0.01,0.01)
for (i in 1:N){
MBHtrue[i] ~ dgamma(meanx^2/varx,meanx/varx)
}
# Likelihood function
for (i in 1:N){
MBH[i]~dnorm(MBHtrue[i],1/errMBH[i]^2);
errorN[i]~dbin(0.5,2*errN_GC[i])
eta[i]<-beta.0+beta.1*MBHtrue[i]
log(mu[i])<-log(exp(eta[i])+errorN[i]-errN_GC[i])
#log(mu[i])<-max(-20,min(20,eta[i]))# Ensures that large beta values do not cause numerical problems.
#p[i]<-size/(size+mu[i])
#N_GC[i]~dnegbin(p[i],size)
#Using mixture of Poisson and Gamma
N_GC[i]~dpois(g[i])
g[i]~dgamma(size,rateParm[i])
rateParm[i]<-size/mu[i]
# Prediction
#etaTrue[i]<-beta.0+beta.1*MBHtrue[i]
#log(muTrue[i])<-max(-20,min(20,etaTrue[i]))
#pTrue[i]<-size/(size+muTrue[i])
#prediction.NB[i]~dnegbin(pTrue[i],size)
# Discrepancy measures
#YNew[i] ~ dnegbin(p[i],size)
YNew[i] ~ dpois(g[i])
varY[i] <- mu[i] + pow(mu[i],2) / size
PRes[i] <-(N_GC[i] - expY[i])/sqrt(varY[i])
PResNew[i] <-(YNew[i] - expY[i])/sqrt(varY[i])
D[i]<-pow(PRes[i],2)
DNew[i]<-pow(PResNew[i],2)
}
Fit<-sum(D[1:N])
New<-sum(DNew[1:N])
# Prediction for new data
for (j in 1:M){
etax[j]<-beta.0+beta.1*MBHx[j]
log(mux[j])<-max(-20,min(20,etax[j]))
#px[j]<-size/(size+mux[j])
#prediction.NBx[j]~dnegbin(px[j],size)
prediction.NBx[j]~dpois(gx[j])
gx[j]~dgamma(size,rateParmx[j])
rateParmx[j]<-size/mux[j]
}
}"
inits1 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
inits2 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
inits3 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
params <- c("beta.0","beta.1","size","PRes","prediction.NB","MBHtrue","Fit","New","prediction.NBx")
#inits1<-function(){list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))}
#jags.neg <- jags.model(
#  data = jags.data,
#  inits = inits,
#  textConnection(model.NB),
#  n.chains = 3,
#  n.adapt=1000
#)
library(parallel)
cl <- makeCluster(3)
jags.neg <- run.jags(method="rjparallel", method.options=list(cl=cl),
data = jags.data,
inits = list(inits1,inits2,inits3),
model=model.NB,
n.chains = 3,
adapt=2000,
monitor=c(params),
burnin=20000,
sample=50000,
summarise=FALSE,
plots=FALSE
)
jagssamples.nb <- as.mcmc.list(jags.neg )
model.NB <- "model{
# Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Prior for size
size~dunif(0.001,10)
# Hyperpriors
meanx ~ dgamma(0.01,0.01)
varx ~ dgamma(0.01,0.01)
for (i in 1:N){
MBHtrue[i] ~ dgamma(meanx^2/varx,meanx/varx)
}
# Likelihood function
for (i in 1:N){
MBH[i]~dnorm(MBHtrue[i],1/errMBH[i]^2);
errorN[i]~dbin(0.5,2*errN_GC[i])
eta[i]<-beta.0+beta.1*MBHtrue[i]
log(mu[i])<-log(exp(eta[i])+errorN[i]-errN_GC[i])
#log(mu[i])<-max(-20,min(20,eta[i]))# Ensures that large beta values do not cause numerical problems.
#p[i]<-size/(size+mu[i])
#N_GC[i]~dnegbin(p[i],size)
#Using mixture of Poisson and Gamma
N_GC[i]~dpois(g[i])
g[i]~dgamma(size,rateParm[i])
rateParm[i]<-size/mu[i]
# Prediction
#etaTrue[i]<-beta.0+beta.1*MBHtrue[i]
#log(muTrue[i])<-max(-20,min(20,etaTrue[i]))
#pTrue[i]<-size/(size+muTrue[i])
#prediction.NB[i]~dnegbin(pTrue[i],size)
# Discrepancy measures
#YNew[i] ~ dnegbin(p[i],size)
YNew[i] ~ dpois(g[i])
expY[i] <- mu[i]
varY[i] <- mu[i] + pow(mu[i],2) / size
PRes[i] <-(N_GC[i] - expY[i])/sqrt(varY[i])
PResNew[i] <-(YNew[i] - expY[i])/sqrt(varY[i])
D[i]<-pow(PRes[i],2)
DNew[i]<-pow(PResNew[i],2)
}
Fit<-sum(D[1:N])
New<-sum(DNew[1:N])
# Prediction for new data
for (j in 1:M){
etax[j]<-beta.0+beta.1*MBHx[j]
log(mux[j])<-max(-20,min(20,etax[j]))
#px[j]<-size/(size+mux[j])
#prediction.NBx[j]~dnegbin(px[j],size)
prediction.NBx[j]~dpois(gx[j])
gx[j]~dgamma(size,rateParmx[j])
rateParmx[j]<-size/mux[j]
}
}"
inits1 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
inits2 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
inits3 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
params <- c("beta.0","beta.1","size","PRes","prediction.NB","MBHtrue","Fit","New","prediction.NBx")
#inits1<-function(){list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))}
#jags.neg <- jags.model(
#  data = jags.data,
#  inits = inits,
#  textConnection(model.NB),
#  n.chains = 3,
#  n.adapt=1000
#)
library(parallel)
cl <- makeCluster(3)
jags.neg <- run.jags(method="rjparallel", method.options=list(cl=cl),
data = jags.data,
inits = list(inits1,inits2,inits3),
model=model.NB,
n.chains = 3,
adapt=2000,
monitor=c(params),
burnin=20000,
sample=50000,
summarise=FALSE,
plots=FALSE
)
jagssamples.nb <- as.mcmc.list(jags.neg )
summary<-extend.jags(jags.neg,drop.monitor=c("PRes","prediction.NB","MBHtrue","Fit","New","prediction.NBx"), summarise=TRUE)
summary
print(summary)
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/NB_GCs/test_for_NB_JAGS")
#Poisson and NB regression using JAGS by Rafael S. de Souza, Bart Buelens, Ewan Cameron
#  Required libraries
library(rjags)
library(ggmcmc)
library(ggplot2)
library(ggthemes)
library(pander)
library(Cairo)
library(plyr)
library(MASS)
library(scales)
require(runjags)
# Script starts here
# Read data
GCS = read.csv(file="..//Dataset//GCs.csv",header=TRUE,dec=".",sep="")
GCS = subset(GCS, !is.na(Mdyn)) # 1 removed
N_err<-GCS$N_GC_err
lowMBH<-GCS$lowMBH
upMBH<-GCS$upMBH
N = nrow(GCS)
######## NB with errors ########################################################
MBHx = seq(from = 0.95 * min(GCS$MBH),
to = 1.05 * max(GCS$MBH),
length.out = 500)
jags.data <- list(
N_GC = GCS$N_GC,
MBH = GCS$MBH,
errN_GC = GCS$N_GC_err,
N = nrow(GCS),
errMBH = upMBH,
MBHx = MBHx,
M = 500
)
model.NB <- "model{
# Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Prior for size
size~dunif(0.001,10)
# Hyperpriors
meanx ~ dgamma(0.01,0.01)
varx ~ dgamma(0.01,0.01)
for (i in 1:N){
MBHtrue[i] ~ dgamma(meanx^2/varx,meanx/varx)
}
# Likelihood function
for (i in 1:N){
MBH[i]~dnorm(MBHtrue[i],1/errMBH[i]^2);
errorN[i]~dbin(0.5,2*errN_GC[i])
eta[i]<-beta.0+beta.1*MBHtrue[i]
log(mu[i])<-log(exp(eta[i])+errorN[i]-errN_GC[i])
p[i]<-size/(size+mu[i])
N_GC[i]~dnegbin(p[i],size)
# Prediction
etaTrue[i]<-beta.0+beta.1*MBHtrue[i]
log(muTrue[i])<-max(-20,min(20,etaTrue[i]))
pTrue[i]<-size/(size+muTrue[i])
prediction.NB[i]~dnegbin(pTrue[i],size)
#prediction.NB[i]~dnegbin(p[i],size)
# Discrepancy measures
YNew[i] ~ dnegbin(p[i],size)
expY[i] <- mu[i]
varY[i] <- mu[i] + pow(mu[i],2) / size
PRes[i] <-(N_GC[i] - expY[i])/sqrt(varY[i])
PResNew[i] <-(YNew[i] - expY[i])/sqrt(varY[i])
D[i]<-pow(PRes[i],2)
DNew[i]<-pow(PResNew[i],2)
}
Fit<-sum(D[1:N])
New<-sum(DNew[1:N])
# Prediction for new data
for (j in 1:M){
etax[j]<-beta.0+beta.1*MBHx[j]
log(mux[j])<-max(-20,min(20,etax[j]))
px[j]<-size/(size+mux[j])
prediction.NBx[j]~dnegbin(px[j],size)
}
}"
inits1 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
inits2 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
inits3 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
params <- c("beta.0","beta.1","size","PRes","prediction.NB","MBHtrue","Fit","New","prediction.NBx")
library(parallel)
cl <- makeCluster(3)
jags.neg <- run.jags(method="rjparallel", method.options=list(cl=cl),
data = jags.data,
inits = list(inits1,inits2,inits3),
model=model.NB,
n.chains = 3,
adapt=2000,
monitor=c(params),
burnin=20000,
sample=50000,
summarise=FALSE,
plots=FALSE
)
jagssamples.nb <- as.mcmc.list(jags.neg )
summary<-extend.jags(jags.neg,drop.monitor=c("PRes","prediction.NB","MBHtrue","Fit","New","prediction.NBx"), summarise=TRUE)
print(summary)
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/NB_GCs/test_for_NB_JAGS")
#  Required libraries
library(rjags)
library(ggmcmc)
library(ggplot2)
library(ggthemes)
library(pander)
library(Cairo)
library(plyr)
library(MASS)
library(scales)
require(runjags)
# Script starts here
# Read data
GCS = read.csv(file="GCs.csv",header=TRUE,dec=".",sep="")
GCS
#NB regression using JAGS by Rafael S. de Souza, Bart Buelens, Ewan Cameron and Joseph Hilbe
#  Required libraries
library(rjags)
library(ggmcmc)
library(ggplot2)
library(ggthemes)
library(pander)
library(Cairo)
library(plyr)
library(MASS)
library(scales)
require(runjags)
# Script starts here
# Read data
GCS = read.csv(file="GCs.csv",header=TRUE,dec=".",sep="")
GCS = subset(GCS, !is.na(Mdyn)) # 1 removed
N_err<-GCS$N_GC_err
lowMBH<-GCS$lowMBH
upMBH<-GCS$upMBH
N = nrow(GCS)
######## NB with errors ########################################################
MBHx = seq(from = 0.95 * min(GCS$MBH),
to = 1.05 * max(GCS$MBH),
length.out = 500)
jags.data <- list(
N_GC = GCS$N_GC,
MBH = GCS$MBH,
errN_GC = GCS$N_GC_err,
N = nrow(GCS),
errMBH = upMBH,
MBHx = MBHx,
M = 500
)
model.NB <- "model{
# Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Prior for size
size~dunif(0.001,10)
# Hyperpriors
meanx ~ dgamma(0.01,0.01)
varx ~ dgamma(0.01,0.01)
for (i in 1:N){
MBHtrue[i] ~ dgamma(meanx^2/varx,meanx/varx)
}
# Likelihood function
for (i in 1:N){
MBH[i]~dnorm(MBHtrue[i],1/errMBH[i]^2);
errorN[i]~dbin(0.5,2*errN_GC[i])
eta[i]<-beta.0+beta.1*MBHtrue[i]
log(mu[i])<-log(exp(eta[i])+errorN[i]-errN_GC[i])
#Using mixture of Poisson and Gamma
N_GC[i]~dpois(g[i])
g[i]~dgamma(size,rateParm[i])
rateParm[i]<-mu[i]/size
# Discrepancy measures
YNew[i] ~ dpois(g[i])
expY[i] <- mu[i]
varY[i] <- mu[i] + pow(mu[i],2) / size
PRes[i] <-(N_GC[i] - expY[i])/sqrt(varY[i])
PResNew[i] <-(YNew[i] - expY[i])/sqrt(varY[i])
D[i]<-pow(PRes[i],2)
DNew[i]<-pow(PResNew[i],2)
}
Fit<-sum(D[1:N])
New<-sum(DNew[1:N])
# Prediction for new data
for (j in 1:M){
etax[j]<-beta.0+beta.1*MBHx[j]
log(mux[j])<-max(-20,min(20,etax[j]))
prediction.NBx[j]~dpois(gx[j])
gx[j]~dgamma(size,rateParmx[j])
rateParmx[j]<-mux[j]/size
}
}"
inits1 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
inits2 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
inits3 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
params <- c("beta.0","beta.1","size","PRes","prediction.NB","MBHtrue","Fit","New","prediction.NBx")
library(parallel)
cl <- makeCluster(3)
jags.neg <- run.jags(method="rjparallel", method.options=list(cl=cl),
data = jags.data,
inits = list(inits1,inits2,inits3),
model=model.NB,
n.chains = 3,
adapt=2000,
monitor=c(params),
burnin=20000,
sample=50000,
summarise=FALSE,
plots=FALSE
)
jagssamples.nb <- as.mcmc.list(jags.neg )
summary<-extend.jags(jags.neg,drop.monitor=c("PRes","prediction.NB","MBHtrue","Fit","New","prediction.NBx"), summarise=TRUE)
print(summary)
exo_dat<-read.table("open_exoplanet_catalogue_kepler.txt", sep="\tab")
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/exoplanets")
exo_dat<-read.table("open_exoplanet_catalogue_kepler.txt", sep="\tab")
exo_dat<-read.table("open_exoplanet_catalogue_kepler.txt", sep="\t")
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/exoplanets")
exo_dat<-read.table("open_exoplanet_catalogue_kepler.txt", sep="\t")
exo_dat[1,]
require(XML)
fileName <- system.file("exampleData", "systems.xml", package="XML")
fileName <- system.file("exampleData", "https://github.com/OpenExoplanetCatalogue/oec_gzip/raw/master/systems.xml.gz", package="XML")
xmlTreeParse(fileName)
xmlTreeParse(fileName)
require(XML)
fileName <- system.file("exampleData", "systems.xml", package="XML")
xmlTreeParse(fileName)
xmlTreeParse("systems.xml")
xmlTreeParse(readLines(systems), asText=TRUE)
xmlTreeParse("systems.xml")
doc<-xmlTreeParse("systems.xml")
r <- xmlRoot(doc)
xmlName(r)
xmlSize(r)
plantcat <- xmlSApply(xmltop, function(x) xmlSApply(x, xmlValue))
# Finally, get the data in a data-frame and have a look at the first rows and columns
plantcat_df <- data.frame(t(plantcat),row.names=NULL)
plantcat_df[1:5,1:4]
plantcat <- xmlSApply(r, function(x) xmlSApply(x, xmlValue))
plantcat_df <- data.frame(t(plantcat),row.names=NULL)
plantcat_df[1:5,1:4]
plantcat
data.frame(plantcat)
print(r)[1:2]
exo_dat<-read.table("exoplanet.eu_catalog.dat",header=TRUE)
exo_dat<-read.table("exoplanet.eu_catalog.dat",sep="\t",header=TRUE)
exo_dat<-read.table("exoplanet.eu_catalog.dat",sep="\t",header=TRUE)
exo_dat
exo_dat[1,]
exo_dat[1:10,]
exo_dat<-read.table("exoplanet.eu_catalog.dat",sep="\t",header=TRUE)
aggregate(exo_dat, by = list(star_name))
aggregate(exo_dat, by = list(star_name),FUN=length)
aggregate(exo_dat, by = list("star_name"),FUN=length)
aggregate(exo_dat, by = list(exo_dat$star_name),FUN=length
)
dim(aggregate(exo_dat, by = list(exo_dat$star_name),FUN=length))
aggregate(exo_dat, by = list(exo_dat$star_name),FUN=length)[1:5]
aggregate(exo_dat, by = list(exo_dat$star_name),FUN=length)[1:5,]
aggregate(exo_dat, by = list(exo_dat$star_name),FUN=length)[1:20,1]
aggregate(exo_dat, by = list(exo_dat$star_name),FUN=length)[1:20,2]
aggregate(exo_dat, by = list(exo_dat$star_name),FUN=length)[1:20,]
aggregate(exo_dat, by = list(exo_dat$star_name),FUN=length)[1:30,]
